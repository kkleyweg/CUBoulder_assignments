---
title: "COVID_Report"
author: "anonymized for grading"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Get the Data

Source from John Hopkins Github

```{r getdata, echo=TRUE}
library(tidyverse)
library(lubridate)
url_in = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/"

file_names = c("time_series_covid19_confirmed_US.csv",  "time_series_covid19_confirmed_global.csv", "time_series_covid19_deaths_US.csv",  "time_series_covid19_deaths_global.csv")

urls = str_c(url_in,file_names)

global_cases = read_csv(urls[2])
global_deaths = read_csv(urls[4])
US_cases = read_csv(urls[1])
US_deaths = read_csv(urls[3])
global_pop = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/refs/heads/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")

```
### Data Cleanup

Now, to clean up and sort the data received. Starting with global, cutting the columns down to country, cases, deaths, population, and date.

```{r global_cleanup, echo=TRUE}
global_cases <- global_cases %>%
  pivot_longer(cols = -c(`Province/State`, `Country/Region`, Lat, Long),
               names_to = "date",
               values_to = "cases") %>%
  select(-c(Lat,Long))

global_deaths <- global_deaths %>%
  pivot_longer(cols = -c(`Province/State`, `Country/Region`, Lat, Long),
               names_to = "date",
               values_to = "deaths") %>%
  select(-c(Lat,Long))

global = global_cases %>%
  full_join(global_deaths) %>%
  rename(Country_Region = `Country/Region`,
         Province_State = `Province/State`) %>%
  mutate(date = mdy(date))

global = global %>% filter(cases > 0)

global = global %>%
  unite("Combined_Key", c(Province_State, Country_Region),
        sep = ", ",
        na.rm = TRUE,
        remove = FALSE)

global = global %>%
  left_join(global_pop, by = c("Province_State", "Country_Region", "Combined_Key")) %>%
  select(-c(UID,FIPS)) %>%
  select(Province_State, Country_Region, date, cases, deaths, Population, Combined_Key)
```

And now to do the same thing for the US data. The final dataframe will contain state, county, cases, deaths, population, and date.

```{r US_cleanup, echo=TRUE}
US_cases <- US_cases %>%
  pivot_longer(cols = -c(UID, iso2, iso3, code3, FIPS, Country_Region, Combined_Key, Province_State, Admin2, Lat, Long_),
               names_to = "date",
               values_to = "cases") %>%
  select(-c(Lat,Long_, UID, iso2, iso3, code3, FIPS, Country_Region, Combined_Key))

US_deaths <- US_deaths %>%
  pivot_longer(cols = -c(UID, iso2, iso3, code3, FIPS, Country_Region, Combined_Key, Population, Province_State, Admin2, Lat, Long_),
               names_to = "date",
               values_to = "deaths") %>%
  select(-c(Lat,Long_, UID, iso2, iso3, code3, FIPS, Combined_Key))

US_all = US_cases %>%
  full_join(US_deaths) %>%
  rename(County = Admin2) %>%
  mutate(date = mdy(date))

US_all = US_all %>%
  unite("Combined_Key",
        c(Province_State, Country_Region),
        sep = ", ",
        na.rm=TRUE,
        remove=FALSE)

```

Now let's make a new table for the US, grouped by state.

```{r us_groupby, echo=TRUE}

US_states = US_all %>%
  group_by(Province_State, Country_Region, date) %>%
  summarize(cases = sum(cases), deaths = sum(deaths), Population = sum(Population)) %>%
  mutate(deaths_per_mill = deaths * 1000000 / Population) %>%
  select(Province_State, Country_Region, date, cases, deaths, deaths_per_mill, Population) %>%
  ungroup()


```
### Visualizations Time!

I'm curious to see how the smallest state in the US was affected by COVID19, so we'll start there. I will graph cases and deaths over time.

```{r viz1, echo=TRUE}

US_states %>%
  filter(cases >0, Province_State=="Rhode Island") %>%
  ggplot(aes(x=date, y=cases)) +
  geom_line(aes(color="cases")) +
  geom_line(aes(y=deaths, color="deaths"))+
  scale_y_log10() +
  theme(legend.position="bottom",
        axis.text.x = element_text(angle=90)) +
  labs(title = "COVID19 in Rhode Island", y=NULL)

```
So we see the initial large rise in cases, then two smaller bumps right before 2021 and just after the start of 2022. Let's see what happens if we are looking at each day, rather than a cumulative count.

```{r viz2, echo=TRUE}

US_states = US_states %>%
  mutate(new_cases = cases - lag(cases),
         new_deaths = deaths - lag(deaths))
US_all = US_all %>%
  mutate(new_cases = cases - lag(cases),
         new_deaths = deaths - lag(deaths))

US_states %>%
  filter(cases >0, Province_State=="Rhode Island") %>%
  ggplot(aes(x=date, y=new_cases)) +
  geom_line(aes(color="new_cases")) +
  geom_line(aes(y=new_deaths, color="new_deaths"))+
  scale_y_log10() +
  theme(legend.position="bottom",
        axis.text.x = element_text(angle=90)) +
  labs(title = "Daily COVID19 in Rhode Island", y=NULL)

```
Here we can see the two largest peaks are the same places we noticed those bumps in the last graph, late 2020 and early 2022. New cases are still showing up! Deaths are thankfully still low.

This last statement makes me wonder... have we gotten better at treating COVID over time, or is it still just as deadly as before? Let's look at that as a mortality ratio, that is deaths/cases. For that we'll zoom back out to full US.

```{r mortality, echo=FALSE}
US_states = US_states %>%
  mutate(mortality = deaths/cases)

US_states %>%
  filter(cases >0) %>%
  ggplot(aes(x=date, y=mortality)) +
  geom_line(aes(color="mortality")) +
  theme(legend.position="bottom",
        axis.text.x = element_text(angle=90)) +
  labs(title = "US COVID19 Mortality Rates", y=NULL)

```
There's some extremely high mortality in the early days, but it looks like it levels off significantly after the start of 2021. Let's build a model based on that.

```{r modeling, echo=TRUE}

mod = lm(mortality ~ date,data=US_states%>%filter(cases>0))

US_pred = US_states%>%filter(cases>0) %>% mutate(pred = predict(mod))

US_pred %>%
  filter(cases >0) %>%
  ggplot(aes(x=date, y=mortality)) +
  geom_line(aes(color="mortality")) +
  geom_line(aes(y=pred, color="pred"))+
  theme(legend.position="bottom",
        axis.text.x = element_text(angle=90)) +
  labs(title = "US COVID19 Mortality Rates", y=NULL)

summary(mod)
```

This leads to an interesting linear fit. The corresponding p-value of this model is 2.2e-16, which would indicate a very good fit. However, we can see from the graph itself that the line steadily trending downward does not match what looks to be an asymptote at 4% mortality. Sometimes a linear fit is not the best fit!

## Bias

This adventure through the COVID19 data surely has some bias throughout. Reporting of cases and deaths could have been under- or overreported. What qualifies as a fatality for COVID may not be what is intended when calculating the mortality of the disease, and I am not a medical professional. 


```{r sessioninfo, echo=FALSE}
sessionInfo()
```
